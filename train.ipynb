{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gKDKHFRFr5EL"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import torch\n",
        "import scipy.io.wavfile as wav\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import math\n",
        "import os\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4iqoPO13sB4y"
      },
      "outputs": [],
      "source": [
        "class Dataset(object):\n",
        "  def __init__(self, data_input, data_target, device):\n",
        "    self.input = torch.from_numpy(data_input).to(device)\n",
        "    self.target = torch.from_numpy(data_target).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lx4IcIbwsHpX"
      },
      "outputs": [],
      "source": [
        "class WavDataset(object):\n",
        "  def __init__(self, frame_size, device, for_processing=False, _wave_sample_rate=44100, _wav_dtype=\"int16\", _wav_channels=1, _DI_path=\"DI.wav\", _target_path=\"target.wav\", ratio=0.8):\n",
        "    # Supported wav format\n",
        "    self._wave_sample_rate = _wave_sample_rate\n",
        "    self._wav_dtype = _wav_dtype\n",
        "    self._wav_channels = _wav_channels\n",
        "    self.device = device\n",
        "    self.frame_size = frame_size\n",
        "\n",
        "    if for_processing == False:\n",
        "      # File paths\n",
        "      self._DI_path = _DI_path\n",
        "      self._target_path = _target_path\n",
        "      self.__load_data(ratio=ratio)\n",
        "    else:\n",
        "      self._raw_path = _DI_path\n",
        "      self.__load_data(for_processing=True)\n",
        "\n",
        "  def __load_data(self, for_processing=False, ratio=0.8):\n",
        "    if for_processing == False:\n",
        "      input_raw = self.__read_wav_file(self._DI_path)\n",
        "      target_raw = self.__read_wav_file(self._target_path)\n",
        "\n",
        "      if len(input_raw) != len(target_raw):\n",
        "        print(\"DI track has {} frames but target track has {} frames\".format(len(input_raw, len(target_raw))))\n",
        "        print(\"Please make sure these 2 files match and have the same length\")\n",
        "        sys.exit()\n",
        "\n",
        "      data_length = len(input_raw)\n",
        "      frame_cnt = math.floor(data_length / self.frame_size)\n",
        "      input_framelized = np.zeros((frame_cnt, self.frame_size, 1), dtype=np.float32)\n",
        "      target_framelized = np.zeros((frame_cnt, self.frame_size, 1), dtype=np.float32)\n",
        "      # Convert 1-D wav data to data frames\n",
        "      for i in range(frame_cnt):\n",
        "        input_framelized[i] = input_raw[i*self.frame_size : (i+1)*self.frame_size].reshape(-1, 1)\n",
        "        target_framelized[i] = target_raw[i*self.frame_size : (i+1)*self.frame_size].reshape(-1, 1)\n",
        "\n",
        "      split_index = int(ratio * frame_cnt)\n",
        "      train_input = input_framelized[:split_index, :]\n",
        "      train_target = target_framelized[:split_index, :]\n",
        "      test_input = input_framelized[split_index:, :]\n",
        "      test_target = target_framelized[split_index:, :]\n",
        "\n",
        "      self.train_set = Dataset(train_input, train_target, device=self.device)\n",
        "      self.test_set = Dataset(test_input, test_target, device=torch.device(\"cpu\"))\n",
        "    else:\n",
        "      input_raw = self.__read_wav_file(self._raw_path)\n",
        "      data_length = len(input_raw)\n",
        "      frame_cnt = math.floor(data_length / self.frame_size)\n",
        "      input_framelized = target_framelized = np.zeros((frame_cnt, self.frame_size, 1), dtype=np.float32)\n",
        "      # Convert 1-D wav data to data frames\n",
        "      for i in range(frame_cnt):\n",
        "        input_framelized[i] = input_raw[i*self.frame_size : (i+1)*self.frame_size].reshape(-1, 1)\n",
        "        self.process_set = torch.from_numpy(input_framelized).to(self.device)\n",
        "\n",
        "  def __read_wav_file(self, path):\n",
        "    print(\"Reading {}...\".format(path))\n",
        "    rate, wavsignal = wav.read(path)\n",
        "\n",
        "    # Check wavfile data format\n",
        "    if ((rate != self._wave_sample_rate) or (wavsignal.dtype != self._wav_dtype) or (wavsignal.ndim != self._wav_channels)):\n",
        "        print(\"Unsupported wav file format: {}Hz, {}bit, {} channels\".format(rate, wavsignal.dtype, wavsignal.ndim))\n",
        "        print(\"Please provide a wav file with {}Hz, {}bit, {} channels\".format(self._wave_sample_rate, self._wav_dtype, self._wav_channels))\n",
        "        sys.exit()\n",
        "\n",
        "    print(\"Successfully read {} with {} samples\".format(path, wavsignal.shape[0]))\n",
        "\n",
        "    wavsignal = np.float32(wavsignal)\n",
        "    wavsignal = wavsignal / 32768.0 # Normalize\n",
        "    return wavsignal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function that checks if a directory exists, and creates it if it doesn't, if dir_name is a list of strings, it will\n",
        "# create a search path, i.e dir_name = ['directory', 'subdir'] will search for directory 'directory/subdir'\n",
        "def dir_check(dir_name):\n",
        "    dir_name = [dir_name] if not type(dir_name) == list else dir_name\n",
        "    dir_path = os.path.join(*dir_name)\n",
        "    if os.path.isdir(dir_path):\n",
        "        pass\n",
        "    else:\n",
        "        os.mkdir(dir_path)\n",
        "\n",
        "\n",
        "# Function that takes a file_name and optionally a path to the directory the file is expected to be, returns true if\n",
        "# the file is found in the stated directory (or the current directory is dir_name = '') or False is dir/file isn't found\n",
        "def file_check(file_name, dir_name=''):\n",
        "    assert type(file_name) == str\n",
        "    dir_name = [dir_name] if ((type(dir_name) != list) and (dir_name)) else dir_name\n",
        "    full_path = os.path.join(*dir_name, file_name)\n",
        "    return os.path.isfile(full_path)\n",
        "\n",
        "\n",
        "# Function that saves 'data' to a json file. Constructs a file path is dir_name is provided.\n",
        "def json_save(data, file_name, dir_name=''):\n",
        "    dir_name = [dir_name] if ((type(dir_name) != list) and (dir_name)) else dir_name\n",
        "    assert type(file_name) == str\n",
        "    file_name = file_name + '.json' if not file_name.endswith('.json') else file_name\n",
        "    full_path = os.path.join(*dir_name, file_name)\n",
        "    with open(full_path, 'w') as fp:\n",
        "        json.dump(data, fp)\n",
        "\n",
        "\n",
        "def json_load(file_name, dir_name=''):\n",
        "    dir_name = [dir_name] if ((type(dir_name) != list) and (dir_name)) else dir_name\n",
        "    file_name = file_name + '.json' if not file_name.endswith('.json') else file_name\n",
        "    full_path = os.path.join(*dir_name, file_name)\n",
        "    with open(full_path) as fp:\n",
        "        return json.load(fp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGTH7HLIsL_o"
      },
      "outputs": [],
      "source": [
        "class RNNModel(nn.Module):\n",
        "  def __init__(self, input_size=1, output_size=1, hidden_size=64, bias=True):\n",
        "    super().__init__()\n",
        "    self.input_size = input_size\n",
        "    self.output_size = output_size\n",
        "    self.bias = bias\n",
        "    self.hidden_size = hidden_size\n",
        "    self.hidden = None\n",
        "\n",
        "    # Create model\n",
        "    self.rec = nn.LSTM(input_size, hidden_size, 1)\n",
        "    self.linear = nn.Linear(hidden_size, output_size, bias=bias)\n",
        "    \n",
        "    # Init weights\n",
        "    for name, param in self.named_parameters():\n",
        "      if 'bias' in name:\n",
        "        nn.init.constant(param, 0.0)\n",
        "      if 'weight' in name:\n",
        "        nn.init.xavier_normal(param)\n",
        "\n",
        "  def forward(self, input):\n",
        "    rec_output, self.hidden = self.rec(input, self.hidden)\n",
        "    output = self.linear(rec_output)\n",
        "    output += input\n",
        "    return output\n",
        "\n",
        "  def reset_hidden(self):\n",
        "    self.hidden = None\n",
        "\n",
        "  def train_epoch(self, loss_function, optimizer, input, target, batch_size):\n",
        "    # Shuffle train set\n",
        "    idx = torch.randperm(input.shape[0])\n",
        "    input = input[idx]\n",
        "    target = target[idx]\n",
        "    # Iterate over the batches, each batch contains several frames\n",
        "    epoch_loss = 0\n",
        "    batch_cnt = math.ceil(input.shape[0] / batch_size)\n",
        "    for i in range(batch_cnt):\n",
        "      input_batch = input[batch_size*i : batch_size*i+batch_size, :, :]\n",
        "      target_batch = target[batch_size*i : batch_size*i+batch_size, :, :]\n",
        "      self.zero_grad()\n",
        "      # Process input batch with neural network\n",
        "      output = self(input_batch)\n",
        "      # Calculate loss and update network parameters\n",
        "      loss = loss_function(output, target_batch)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      self.reset_hidden()\n",
        "      if i % 10 == 0:\n",
        "        print(\"Frame {}/{}: {:.2%}, loss = {}\".format(i, batch_cnt, i/batch_cnt, loss), end='\\r')\n",
        "      epoch_loss += loss\n",
        "    print(\"\")\n",
        "    return epoch_loss / (i + 1)\n",
        "\n",
        "  def predict(self, input, batch_size=4096):\n",
        "    torch.no_grad()\n",
        "    output = torch.empty_like(input).to(torch.device(\"cpu\"))\n",
        "    batch_cnt = math.ceil(len(input) / batch_size)\n",
        "    for i in range(batch_cnt):\n",
        "      print(\"Process batch {}/{}: {:.2%}\".format(i, batch_cnt, i/batch_cnt))\n",
        "      output[batch_size*i : batch_size*i+batch_size] = self(input[batch_size*i : batch_size*i+batch_size, :])\n",
        "      self.reset_hidden()\n",
        "    return output\n",
        "  \n",
        "  def save_model(self, file_name, direc=''):\n",
        "    if direc:\n",
        "      dir_check(direc)\n",
        "    model_data = {'model_data': {'model': 'RNN', 'input_size': self.rec.input_size,\n",
        "                                 'output_size': self.linear.out_features, 'unit_type': self.rec._get_name(),\n",
        "                                  'num_layers': self.rec.num_layers, 'hidden_size': self.rec.hidden_size,\n",
        "                                  'bias_fl': self.bias}}\n",
        "    model_state = self.state_dict()\n",
        "    for each in model_state:\n",
        "      model_state[each] = model_state[each].tolist()\n",
        "    model_data['state_dict'] = model_state\n",
        "    json_save(model_data, file_name, direc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TiFLLeiysez4"
      },
      "outputs": [],
      "source": [
        "def train_model(model: RNNModel, loss_function, epochs,\n",
        "          optimizer: torch.optim.Optimizer, wav_dataset: WavDataset, batch_size, lr):\n",
        "  for i in range(epochs):\n",
        "    # Run a train epoch\n",
        "    print(\"Train epoch {}\".format(i+1))\n",
        "    if i > 1:\n",
        "      lr /= 1.5\n",
        "    for param_group in optimizer.param_groups:\n",
        "      param_group['lr'] = lr\n",
        "    epoch_loss = model.train_epoch(loss_function, optimizer, wav_dataset.train_set.input, wav_dataset.train_set.target, batch_size)\n",
        "    print(\"Epoch loss = {}\".format(epoch_loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sn5L72BKsi_u",
        "outputId": "c17c7dc1-d81c-4409-acb9-bacae0176a40"
      },
      "outputs": [],
      "source": [
        "# Train paramters\n",
        "model = RNNModel(hidden_size=96)\n",
        "print(model)\n",
        "loss_function = nn.MSELoss()\n",
        "epochs = 100\n",
        "lr = 0.01\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda:0\")\n",
        "  torch.cuda.empty_cache()\n",
        "  print(\"Running on the GPU\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "  print(\"Running on the CPU\")\n",
        "\n",
        "# device = torch.device(\"cpu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Start training\n",
        "model.to(device)\n",
        "wav_dataset = WavDataset(frame_size=4410, device=device) # Load wav files as datasets, 100ms per frame\n",
        "# train_input = torch.flatten(wav_dataset.train_set.input).to(torch.device(\"cpu\")).numpy()\n",
        "# train_target = torch.flatten(wav_dataset.train_set.target).to(torch.device(\"cpu\")).numpy()\n",
        "# test_input = torch.flatten(wav_dataset.test_set.input).to(torch.device(\"cpu\")).numpy()\n",
        "# test_target = torch.flatten(wav_dataset.test_set.target).to(torch.device(\"cpu\")).numpy()\n",
        "# plt.figure(1)\n",
        "# plt.plot(train_input, label=\"train_input\")\n",
        "# plt.figure(2)\n",
        "# plt.plot(train_target, label=\"train_target\")\n",
        "# plt.figure(3)\n",
        "# plt.plot(test_input, label=\"test_input\")\n",
        "# plt.figure(4)\n",
        "# plt.plot(test_target, label=\"test_target\")\n",
        "# plt.legend()\n",
        "# plt.show()\n",
        "train_model(model=model, loss_function=loss_function, epochs=epochs, optimizer=optimizer,wav_dataset=wav_dataset, batch_size=40, lr=lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "IUC8wlx9vs2E",
        "outputId": "6447fa2b-88ea-4da4-d8f9-64ba7ddac1a8"
      },
      "outputs": [],
      "source": [
        "# Test model\n",
        "model.to(torch.device(\"cpu\"))\n",
        "wav_dataset.test_set.target.to(torch.device(\"cpu\"))\n",
        "wav_dataset.test_set.input.to(torch.device(\"cpu\"))\n",
        "before = wav_dataset.test_set.input\n",
        "trained = model.predict(wav_dataset.test_set.input)\n",
        "# Calculate accuracy\n",
        "trained = torch.flatten(trained).detach().numpy()\n",
        "target = torch.flatten(wav_dataset.test_set.target).detach().numpy()\n",
        "before = torch.flatten(before).detach().numpy()\n",
        "\n",
        "accuracy = 0\n",
        "for i in range(len(trained)):\n",
        "    if trained[i] - target[i] < 1e-4:\n",
        "        accuracy += 1\n",
        "accuracy /= i\n",
        "print(\"Test accuracy = {:.2%}\".format(accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "FuMXb9_tvZmx",
        "outputId": "1215d865-25c8-4e9e-c4d5-8db700dc7ca1"
      },
      "outputs": [],
      "source": [
        "# Plot test result\n",
        "plt.figure(1)\n",
        "plt.plot(target[:500], color=\"green\", label=\"Target\")\n",
        "plt.plot(trained[:500], color=\"red\", label=\"Trained result\")\n",
        "plt.plot(before[:500], color=\"yellow\", label=\"Before training\")\n",
        "plt.xlabel(\"Sample\")\n",
        "plt.ylabel(\"Normalized value\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "# for param in model.parameters():\n",
        "#     print(param)\n",
        "torch.save(model, \"demo.pth\")\n",
        "model.save_model(\"marshall.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trained = np.int16(trained)\n",
        "before = np.int16(before)\n",
        "plt.plot(trained, label=\"Trained wav file\")\n",
        "plt.plot(before, label=\"Raw wav file\")\n",
        "plt.xlabel(\"Sample\")\n",
        "plt.ylabel(\"Normalized value\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "wav.write(\"output.wav\", 44100, trained)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Process raw sound\n",
        "torch.cuda.empty_cache()\n",
        "test_model = torch.load(\"demo.pth\")\n",
        "for param in test_model.parameters():\n",
        "    param.requires_grad = False\n",
        "test_model.eval()\n",
        "test_model.to(device=torch.device(\"cpu\"))\n",
        "\n",
        "input = WavDataset(frame_size=4096, device=torch.device(\"cpu\"), for_processing=True, _DI_path=\"raw.wav\").process_set\n",
        "output = test_model.predict(input)\n",
        "output = torch.flatten(output.to(torch.device(\"cpu\"))).detach().numpy()\n",
        "input = torch.flatten(input.to(torch.device(\"cpu\"))).detach().numpy()\n",
        "output = np.int16(output)\n",
        "input = np.int16(input)\n",
        "plt.plot(output[100000:101000], label=\"Output wav file\")\n",
        "plt.plot(input[100000:101000], label=\"Input wav file\")\n",
        "plt.xlabel(\"Sample\")\n",
        "plt.ylabel(\"Normalized value\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "wav.write(\"processed.wav\", rate=44100, data=output)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "3e88015cdadecd184e2a3105d4563edd488d588a329b7a196851269bb10d0253"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
